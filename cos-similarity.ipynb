{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 讀入gept初、中、中高之字典\n",
    "word1 = open('gept1.txt','r')\n",
    "word2 = open('gept2.txt','r')\n",
    "word3 = open('gept3.txt','r')\n",
    "gept1 = word1.read().split(sep = '\\n')\n",
    "gept2 = word2.read().split(sep = '\\n')\n",
    "gept3 = word3.read().split(sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#讀入文章、分類及停止詞庫\n",
    "news = open('Content.txt','r').read().split(sep = '^')\n",
    "catagory = open('Catagory.txt','r').read().split(sep = '\\n')\n",
    "stopword = open('stopwords.txt','r').read().split(sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#刪除中文標點符號\n",
    "content1 = []\n",
    "for i in range(0,len(news)):        \n",
    "    new = re.sub('[！？｡＂＃＄％＆＇（）＊＋，－／：；＜＝＞＠［＼］＾＿｀｛｜｝～｟｠｢｣､、〃》「」『』【】〔〕〖〗〘〙〚〛〜〝〞〟〰〾〿–—‘’‛“”„‟…‧﹏.]', '', news[i])\n",
    "    content1.append(new)\n",
    "\n",
    "#刪除英文標點符號\n",
    "content = []\n",
    "for j in range(0,len(content1)):\n",
    "    n = re.sub('[%s]' % re.escape(string.punctuation), '', content1[j])\n",
    "    content.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#定義停止詞及刪除空白\n",
    "space = ' '\n",
    "stopword.append(space)\n",
    "def removeStopword(word_list,stop):\n",
    "    return [w for w in word_list if w not in stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/qh/8bdz64w16cv0_y5098f1g5440000gn/T/jieba.cache\n",
      "Loading model cost 1.249 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "#使用結巴斷詞\n",
    "content_list = []\n",
    "for c in range(0,len(content)):\n",
    "    lst = removeStopword(jieba.lcut(content[c].lower(),cut_all=False),stopword)\n",
    "    content_list.append(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#加入字典，並去除停止詞\n",
    "content_list.append(removeStopword(gept1,stopword))\n",
    "content_list.append(removeStopword(gept2,stopword))\n",
    "content_list.append(removeStopword(gept3,stopword))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#得到全文章的term dictionary\n",
    "term_dict = []\n",
    "for i in range(0,len(content_list)):\n",
    "    term_dict.extend(content_list[i])\n",
    "term_dict = list(set(term_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#定義func來計算tf (use numpy to create array)。\n",
    "def termFrequency(doctoken):\n",
    "    tf_vector = np.zeros([len(term_dict),1])\n",
    "    for t in doctoken:\n",
    "        tf_vector[term_dict.index(t),0] = doctoken.count(t)\n",
    "    return tf_vector\n",
    "\n",
    "tf_doc = []\n",
    "for d in range(0,len(content_list)):\n",
    "    tf_doc.append(termFrequency(content_list[d]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#用numpy產生空的idf_vector，定義func計算idf (先求df再利用判斷式判斷df值，並藉此計算idf值，後塞入idf_vector)。\n",
    "idf_vector = np.zeros([len(term_dict),1])\n",
    "def inverseDocumentFrequency(term):\n",
    "    numDocumentsWithThisTerm = 0\n",
    "    for doc in range(0,len(content_list)):\n",
    "            if term in content_list[doc]:\n",
    "                numDocumentsWithThisTerm = numDocumentsWithThisTerm + 1\n",
    "    \n",
    "    if numDocumentsWithThisTerm > 0:\n",
    "        idf_vector[term_dict.index(term),0] = math.log10(float(len(content_list)) / numDocumentsWithThisTerm)\n",
    "    else:\n",
    "        idf_vector[term_dict.index(term),0] = 0\n",
    "    return idf_vector\n",
    "\n",
    "for t in term_dict:\n",
    "    inverseDocumentFrequency(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#求tfidf，迴圈對每篇document的tf值去乘上idf值。\n",
    "tfidf_doc = []\n",
    "for doc in range(0,len(tf_doc)):\n",
    "    tfidf_doc.append(tf_doc[doc]*idf_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#定義func，一個計算tfidf值的平方和開根號，另一個計算相似度。\n",
    "def sqrt_sum_square(tfidf):\n",
    "    return np.sqrt(sum(np.square(tfidf)))\n",
    "    \n",
    "def similarity(tfidf1,tfidf2): \n",
    "    return (np.dot(tfidf1.T,tfidf2)[0][0]) / ((sqrt_sum_square(tfidf1)[0]) * (sqrt_sum_square(tfidf2)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for迴圈計算各doc與初、中、中高級字典的相似度（因為起始值為0所以為7332,7333,7334）。\n",
    "sim1 = []\n",
    "for i in range(0,len(tfidf_doc)):\n",
    "    sim1.append(similarity(tfidf_doc[7332],tfidf_doc[i]))\n",
    "\n",
    "sim2 = []\n",
    "for j in range(0,len(tfidf_doc)):\n",
    "    sim2.append(similarity(tfidf_doc[7333],tfidf_doc[j]))\n",
    "\n",
    "sim3 = []\n",
    "for k in range(0,len(tfidf_doc)):\n",
    "    sim3.append(similarity(tfidf_doc[7334],tfidf_doc[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#運用邏輯判斷式，判斷各篇文章的類別（初級：1,中級：2,中高級：3）\n",
    "Similar_Label = []\n",
    "for i in range(0,len(sim1)):\n",
    "    if sim1[i] > sim2[i] and sim1[i] > sim3[i]:\n",
    "        Similar_Label.append('1')\n",
    "    elif sim2[i] > sim1[i] and sim2[i] > sim3[i]:\n",
    "        Similar_Label.append('2')\n",
    "    else:\n",
    "        Similar_Label.append('3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#使用pandas dataframe 儲存文章內文，類別，相似度分類\n",
    "d = {'Content' : pd.Series(news),\n",
    "     'Catagory' : pd.Series(catagory),\n",
    "     'Similar_Label' : pd.Series(Similar_Label[0:7332])}\n",
    "df = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#存成csv檔匯出\n",
    "df.to_csv('cosine_similarity.csv',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#另存一個包含3個相似度的，免得之後要重跑一次\n",
    "d = {'Content' : pd.Series(news),\n",
    "     'Catagory' : pd.Series(catagory),\n",
    "     'Similar_Label' : pd.Series(Similar_Label[0:7332]),\n",
    "     'Gept1_Similar' : pd.Series(sim1[0:7332]),\n",
    "     'Gept2_Similar' : pd.Series(sim2[0:7332]),\n",
    "     'Gept3_Similar' : pd.Series(sim3[0:7332])}\n",
    "df = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#存成csv檔匯出\n",
    "df.to_csv('cosine_similarity_with_sim1to3.csv',header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310\n",
      "496\n",
      "737\n",
      "1044\n",
      "1262\n",
      "1409\n",
      "1627\n",
      "1833\n",
      "2051\n",
      "2313\n",
      "2531\n",
      "2859\n",
      "3077\n",
      "3466\n",
      "3684\n",
      "4136\n",
      "4354\n",
      "4873\n",
      "5091\n",
      "5675\n",
      "5893\n",
      "6541\n",
      "6759\n"
     ]
    }
   ],
   "source": [
    "#我用這個驗證位置有沒有出錯\n",
    "for i in range(0,7333):\n",
    "    if Similar_Label[i] == '3':\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
