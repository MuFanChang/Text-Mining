{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Defensive drivers look in their driving mirror...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Egypt's Antiquities Ministry announced that it...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Don't miss this once-in-a-lifetime opportunity...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               article  rating\n",
       "54   Defensive drivers look in their driving mirror...       2\n",
       "146  Egypt's Antiquities Ministry announced that it...       2\n",
       "63   Don't miss this once-in-a-lifetime opportunity...       2"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(0)\n",
    "df = pd.read_csv('./gepd.csv',encoding = \"ISO-8859-1\")  # \n",
    "\n",
    "df = df.reindex(np.random.permutation(df.index))  # 打亂 df 的排序 np.random.permutation()\n",
    "\n",
    "#df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 詞袋模型: 句子 -> 單字 -> 詞袋(稀疏矩陣)\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 計算 TF-IDF, 使用 L2正規化 \n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf = TfidfTransformer(use_idf=True, norm='l2', smooth_idf=True)\n",
    "#print(tfidf.fit_transform(count.fit_transform(docs)).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 文件清理\n",
    "# 用正規表示式\n",
    "import re\n",
    "def preprocessor(text):\n",
    "    text = re.sub('<[^>]*>', '', text) # 清除 HTML\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text) # 清除 標點符號\n",
    "    text = re.sub('[\\W]+', ' ', text.lower()) + \\\n",
    "           ' '.join(emoticons).replace('-', '') # 非字元符號, - \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 所有文本清除前\n",
    "#print(df['article'].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54     defensive drivers look in their driving mirror...\n",
      "146    egypt s antiquities ministry announced that it...\n",
      "63     don t miss this once in a lifetime opportunity...\n",
      "55     according to newspaper reports flooding in the...\n",
      "125    in modern hospitals the most popular treatment...\n",
      "100    some of curt wilder s books have been widely r...\n",
      "7      elementary school students don t have as much ...\n",
      "155    the european union s regulator sent microsoft ...\n",
      "104    the digital age is dawning and that s good new...\n",
      "89     in public service lectures fire fighters not o...\n",
      "138    former nazi ss officer oskar groening known as...\n",
      "143    sometimes being friendly and flashing a big sm...\n",
      "5      the student raced out of the classroom and bum...\n",
      "97     bruce read two film scripts he didn t enjoy on...\n",
      "163    chiloe a beautiful island chain lies off the c...\n",
      "93     the current economic recession is threatening ...\n",
      "33     the babysitter has been with the child since t...\n",
      "18     dear grandma and grandpa thank you so much for...\n",
      "61     manners are the ways in which people behave in...\n",
      "51     construction of the new highway system would h...\n",
      "Name: article, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 所有文本清除後\n",
    "df['article'] = df['article'].apply(preprocessor)\n",
    "#print(df['article'].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 文件轉為字符\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def tokenizer(text):  # 方法1. 空白字元斷字\n",
    "    return text.split()\n",
    "def tokenizer_porter(text): # 方法2. 字詞 -> 字根\n",
    "    return [porter.stem(word) for word in text.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Administrator\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# 命令提示字元 執行 pip install nltk\n",
    "# 處理停用字(常見但又無用的字, is and or...)\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# 使用英文停用字集\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.loc[:,'article'], df.loc[:, 'rating'], test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35,)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train.shape\n",
    "#y_train.shape\n",
    "#X_test.shape\n",
    "#y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for SVC(kernel=rbf)\n",
      "Training time: 0.006412s; Prediction time: 0.000000s\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.00      0.00      0.00        10\n",
      "          2       0.43      1.00      0.60        15\n",
      "          3       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.18      0.43      0.26        35\n",
      "\n",
      "Results for SVC(kernel=linear)\n",
      "Training time: 0.005343s; Prediction time: 0.001069s\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.86      0.60      0.71        10\n",
      "          2       0.60      1.00      0.75        15\n",
      "          3       1.00      0.30      0.46        10\n",
      "\n",
      "avg / total       0.79      0.69      0.65        35\n",
      "\n",
      "Results for LinearSVC()\n",
      "Training time: 0.001069s; Prediction time: 0.001069s\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.86      0.60      0.71        10\n",
      "          2       0.60      0.80      0.69        15\n",
      "          3       0.50      0.40      0.44        10\n",
      "\n",
      "avg / total       0.64      0.63      0.62        35\n",
      "\n",
      "Results for MultinomialNB\n",
      "Training time: 0.001069s; Prediction time: 0.001069s\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      0.30      0.46        10\n",
      "          2       0.47      1.00      0.64        15\n",
      "          3       0.00      0.00      0.00        10\n",
      "\n",
      "avg / total       0.49      0.51      0.41        35\n",
      "\n",
      "Results for BernoulliNB\n",
      "Training time: 0.001069s; Prediction time: 0.000000s\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      1.00      0.67        10\n",
      "          2       0.80      0.53      0.64        15\n",
      "          3       0.60      0.30      0.40        10\n",
      "\n",
      "avg / total       0.66      0.60      0.58        35\n",
      "\n",
      "Results for KNN\n",
      "Training time: 0.001069s; Prediction time: 0.001069s\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.57      0.40      0.47        10\n",
      "          2       0.00      0.00      0.00        15\n",
      "          3       0.36      1.00      0.53        10\n",
      "\n",
      "avg / total       0.27      0.40      0.28        35\n",
      "\n",
      "Results for LogisticRegression\n",
      "Training time: 0.347327s; Prediction time: 0.000000s\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       1.00      0.30      0.46        10\n",
      "          2       0.48      1.00      0.65        15\n",
      "          3       1.00      0.10      0.18        10\n",
      "\n",
      "avg / total       0.78      0.54      0.46        35\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1113: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "    \n",
    "# Create feature vectors\n",
    "vectorizer = TfidfVectorizer(min_df=5,\n",
    "                             max_df = 0.8,\n",
    "                             sublinear_tf=True,\n",
    "                             stop_words=stop,\n",
    "                              tokenizer=tokenizer_porter,\n",
    "                             use_idf=True)\n",
    "train_vectors = vectorizer.fit_transform(X_train)\n",
    "test_vectors = vectorizer.transform(X_test)\n",
    "\n",
    "# Perform classification with SVM, kernel=rbf\n",
    "classifier_rbf = svm.SVC()\n",
    "t0 = time.time()\n",
    "fit_svm_rbf = classifier_rbf.fit(train_vectors, y_train)\n",
    "t1 = time.time()\n",
    "prediction_rbf = classifier_rbf.predict(test_vectors)\n",
    "t2 = time.time()\n",
    "time_rbf_train = t1-t0\n",
    "time_rbf_predict = t2-t1\n",
    "\n",
    "# Perform classification with SVM, kernel=linear\n",
    "classifier_linear = svm.SVC(kernel='linear')\n",
    "t0 = time.time()\n",
    "fit_svm_linear = classifier_linear.fit(train_vectors, y_train)\n",
    "t1 = time.time()\n",
    "prediction_linear = classifier_linear.predict(test_vectors)\n",
    "t2 = time.time()\n",
    "time_linear_train = t1-t0\n",
    "time_linear_predict = t2-t1\n",
    "\n",
    "# Perform classification with SVM, kernel=linear\n",
    "classifier_liblinear = svm.LinearSVC()\n",
    "t0 = time.time()\n",
    "fit_svm_liblinear = classifier_liblinear.fit(train_vectors, y_train)\n",
    "t1 = time.time()\n",
    "prediction_liblinear = classifier_liblinear.predict(test_vectors)\n",
    "t2 = time.time()\n",
    "time_liblinear_train = t1-t0\n",
    "time_liblinear_predict = t2-t1\n",
    "\n",
    "\n",
    "\n",
    "# Perform classification with naive_bayes, kernel=MultinomialNB\n",
    "#clf = MultinomialNB()\n",
    "classifier_MultinomialNB = MultinomialNB(alpha=1.0, fit_prior=True)\n",
    "t0 = time.time()\n",
    "fit_MultinomialNB = classifier_MultinomialNB.fit(train_vectors, y_train)\n",
    "t1 = time.time()\n",
    "prediction_MultinomialNB = classifier_MultinomialNB.predict(test_vectors)\n",
    "t2 = time.time()\n",
    "time_MultinomialNB_train = t1-t0\n",
    "time_MultinomialNB_predict = t2-t1\n",
    "\n",
    "\n",
    "# Perform classification with naive_bayes, kernel=BernoulliNB\n",
    "#clf = BernoulliNB()\n",
    "classifier_BernoulliNB = BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
    "t0 = time.time()\n",
    "fit_BernoulliNB = classifier_BernoulliNB.fit(train_vectors, y_train)\n",
    "t1 = time.time()\n",
    "prediction_BernoulliNB = classifier_BernoulliNB.predict(test_vectors) \n",
    "t2 = time.time()\n",
    "time_BernoulliNB_train = t1-t0\n",
    "time_BernoulliNB_predict = t2-t1\n",
    "\n",
    "\n",
    "# Perform classification with KNN\n",
    "classifier_neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "t0 = time.time()\n",
    "fit_KNN = classifier_neigh.fit(train_vectors, y_train)\n",
    "t1 = time.time()\n",
    "prediction_KNN =classifier_neigh.predict(test_vectors)\n",
    "t2 = time.time()\n",
    "time_KNN_train = t1-t0\n",
    "time_KNN_predict = t2-t1\n",
    "\n",
    "\n",
    "\n",
    "# Perform classification with LogisticRegression\n",
    "classifier_Logistic = LogisticRegression()\n",
    "t0 = time.time()\n",
    "Logistic_KNN = classifier_Logistic.fit(train_vectors, y_train)\n",
    "t1 = time.time()\n",
    "prediction_Logistic = classifier_Logistic.predict(test_vectors)\n",
    "t2 = time.time()\n",
    "time_Logistic_train = t1-t0\n",
    "time_Logistic_predict = t2-t1\n",
    "\n",
    "\n",
    "\n",
    "# Print results in a nice table\n",
    "print(\"Results for SVC(kernel=rbf)\")\n",
    "print(\"Training time: %fs; Prediction time: %fs\" % (time_rbf_train, time_rbf_predict))\n",
    "print(classification_report(y_test, prediction_rbf))\n",
    "\n",
    "print(\"Results for SVC(kernel=linear)\")\n",
    "print(\"Training time: %fs; Prediction time: %fs\" % (time_linear_train, time_linear_predict))\n",
    "print(classification_report(y_test, prediction_linear))\n",
    "\n",
    "print(\"Results for LinearSVC()\")\n",
    "print(\"Training time: %fs; Prediction time: %fs\" % (time_liblinear_train, time_liblinear_predict))\n",
    "print(classification_report(y_test, prediction_liblinear))\n",
    "\n",
    "print(\"Results for MultinomialNB\")\n",
    "print(\"Training time: %fs; Prediction time: %fs\" % (time_MultinomialNB_train, time_MultinomialNB_predict))\n",
    "print(classification_report(y_test, prediction_MultinomialNB))\n",
    "\n",
    "print(\"Results for BernoulliNB\")\n",
    "print(\"Training time: %fs; Prediction time: %fs\" % (time_BernoulliNB_train, time_BernoulliNB_predict))\n",
    "print(classification_report(y_test, prediction_BernoulliNB))\n",
    "\n",
    "print(\"Results for KNN\")\n",
    "print(\"Training time: %fs; Prediction time: %fs\" % (time_KNN_train, time_KNN_predict))\n",
    "print(classification_report(y_test, prediction_KNN))\n",
    "\n",
    "print(\"Results for LogisticRegression\")\n",
    "print(\"Training time: %fs; Prediction time: %fs\" % (time_Logistic_train, time_Logistic_predict))\n",
    "print(classification_report(y_test, prediction_Logistic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
